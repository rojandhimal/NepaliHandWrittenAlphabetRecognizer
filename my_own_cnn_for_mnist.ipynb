{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_own_cnn_for_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rojan116/NepaliHandWrittenAlphabetRecognizer/blob/master/my_own_cnn_for_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrusueHqDZXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = np.array([[3,3,3],\n",
        "             [3,2,0],\n",
        "             [-1,2,-4]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrCS6-yYDgvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "81e920c4-0f15-4a12-f20e-da857a51fec7"
      },
      "source": [
        "y = np.maximum(x,0)\n",
        "y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 3, 3],\n",
              "       [3, 2, 0],\n",
              "       [0, 2, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr34HtAKF_uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=[1,4,5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMgeGww0DvIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_size = 10\n",
        "def convert_y(a):\n",
        "    arr = np.zeros((output_size,1))\n",
        "    arr[a] = 1\n",
        "    return arr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShcVBbCJDw5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "efb95e37-8e5e-444e-d344-bb55240a7259"
      },
      "source": [
        "convert_y(a)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbNYpuXgEiZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u=np.zeros((output_size,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQWZQ-f6Fstj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a80978a2-e1de-42fa-f3fb-9631ceb5241b"
      },
      "source": [
        "u"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LBvvr-VFxDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c960ea00-277a-4ee7-a943-984ec41da2ce"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import copy\n",
        "from random import randint\n",
        "\n",
        "#reading mnist dataset\n",
        "#load dataset\n",
        "MNIST_data = h5py.File('MNISTdata.hdf5', 'r')\n",
        "#training set\n",
        "x_train = np.float32(MNIST_data['x_train'][:] )\n",
        "y_train = np.int32(np.array(MNIST_data['y_train'][:,0]))\n",
        "#test set\n",
        "x_test = np.float32( MNIST_data['x_test'][:] )\n",
        "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
        "MNIST_data.close()\n",
        "\n",
        "#number of training set\n",
        "print(x_train.shape)\n",
        "#number of test set\n",
        "print(x_test.shape)\n",
        "#display size of dataset image\n",
        "print(x_train[0].shape)\n",
        "print(x_test[0].shape)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(784,)\n",
            "(784,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANMllVdQ7LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_inputs = len(x_train) #number training set\n",
        "output_size = 10  #number of class\n",
        "num_filters=5     #number of filter used in convolution layer\n",
        "filter_size=3     #size of filter/kernel\n",
        "input_dim=28      #input dimension\n",
        "input_size=28*28  #input size\n",
        "\n",
        "LR = .01          #learning Rate\n",
        "num_epochs = 10   #Epochs \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z7JJFkZRLAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#K is N number of n*n  size filter\n",
        "K = np.random.randn(filter_size,filter_size, num_filters)/ np.sqrt(filter_size)\n",
        "\n",
        "#initial random weight\n",
        "W = np.random.randn(output_size,input_dim-filter_size+1,input_dim-filter_size+1,num_filters) / np.sqrt(input_dim-filter_size+1)\n",
        "\n",
        "#initial bias values\n",
        "bias= np.zeros((output_size, 1))/np.sqrt(output_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymZo7597RXWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ee159f78-c9c2-40d4-9210-a122246e7cee"
      },
      "source": [
        "#number of filter\n",
        "print(K.shape)\n",
        "#number of random weights\n",
        "print(W.shape)\n",
        "#number of bias \n",
        "print(bias.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3, 5)\n",
            "(10, 26, 26, 5)\n",
            "(10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIr1uGcRRazM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convolutional layer\n",
        "def conv(x,K):\n",
        "\t#Z=np.zeros((input_dim-filter_size+1,input_dim-filter_size+1,num_filters))\n",
        "\tZ=np.zeros(((x.shape[0]-K.shape[0]+1),(x.shape[0]-K.shape[0]+1),K.shape[2]))\n",
        "\t\n",
        "\tfor p in range(K.shape[2]):\n",
        "\t\tfor i in range(Z.shape[0]):\n",
        "\t\t\tfor j in range(Z.shape[1]):\n",
        "\t\t\t\t\tif (i+3<Z.shape[0] and j+3<Z.shape[1]):\n",
        "\t\t\t\t\t\tx_temp = x[i:i+3,j:j+3]\n",
        "\t\t\t\t\t\ttemp=np.multiply(x_temp,K[:,:,p])\n",
        "\t\t\t\t\t\tZ[i,j,p]=np.sum(temp)\n",
        "\treturn Z\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki4WDxp3T-rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encoding\n",
        "def convert_y(y):\n",
        "    arr = np.zeros((output_size,1))  #initialize id array of output size \n",
        "    arr[y] = 1       #assign 1 to value of array at index y\n",
        "    return arr       #return one hot encoded array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIBd87yRUDJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#softmax activation function\n",
        "def softmax_function(z):\n",
        "    ZZ = np.exp(z - max(z))/np.sum(np.exp(z - max(z)))   \n",
        "    return ZZ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ79QSeTUHmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#relu activation function\n",
        "def Relu(z):\n",
        "    return np.maximum(z,0)    #return zero for those value less than zero if x<0 then x=0 else x =x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UmloUVVpAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gardient relu activation function\n",
        "def gradient_Relu(z):\n",
        "    return np.where(z>0,1,0)  #return zero for value less than zero else return 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRrNxwyrVwQv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f7fb7ad9-3a3c-449f-ae1a-348b977789fb"
      },
      "source": [
        "Relu(x)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 3, 3],\n",
              "       [3, 2, 0],\n",
              "       [0, 2, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDeMZm9JV3ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b094debe-b07e-4a04-8c0f-76ccff640f18"
      },
      "source": [
        "gradient_Relu(x) "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [1, 1, 0],\n",
              "       [0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoBOfcHIdpAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x_train[n_random][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7FYcIQXdp9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31f6f1a1-7da4-4dfb-b731-2c3d79e8a1ca"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWln2sgUdr8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oDdrFC5V8oT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fitting model\n",
        "for epochs in range(num_epochs):   #looping through number of epochs\n",
        "\n",
        "    if (epochs > 5):               \n",
        "        LR = 0.001                  #set learning rate 0.001 if epohs >5 \n",
        "    if (epochs > 10):\n",
        "        LR = 0.0001                 #set learning rate 0.0001 if epohs >10\n",
        "    if (epochs > 15):\n",
        "        LR = 0.00001                #set learning rate 0.00001 if epohs >15 \n",
        "\n",
        "    total_correct = 0               #initialize count variable to store correct count\n",
        "\n",
        "    for n in range(len(x_train)):    #looping through number of training image\n",
        "        n_random = randint(0,len(x_train)-1)  #shuffel dataset randomly\n",
        "        y = y_train[n_random]                 #corresponding label of shuffeled data\n",
        "        x = x_train[n_random][:]              #random data \n",
        "        x = np.reshape(x, (input_dim, input_dim))  #reshape random data\n",
        "\n",
        "      #creating CNN \n",
        "      \n",
        "      #forward propagation\n",
        "\n",
        "        Z=conv(x,K)                  #convolving image\n",
        "        H=Relu(Z)                    #feeding output of conv layer to relu layer\n",
        "        \n",
        "        U=np.zeros((output_size,1))  #initailizing 1D array of category\n",
        "        for i in range(output_size):  #looping through nurens\n",
        "        \ttemp1=W[i,:,:,:]            #holding weight w of nuron i\n",
        "        \ttemp2=np.multiply(temp1,H)  #perform wx ie weight * x\n",
        "        \tU[i]=np.sum(temp2) + bias[i] #add bias ie Wx+b\n",
        "        \n",
        "        rho = softmax_function(U)      #calulate probability of image being in every category\n",
        "        predicted_value = np.argmax(rho) #select probability with highest score\n",
        "\n",
        "        if (predicted_value == y):     # if predicted output matches actual output inccrement count varuable\n",
        "            total_correct += 1\n",
        "\n",
        "        #backward propagation\n",
        "        #updating filter weight\n",
        "        \n",
        "        diff_U = rho - convert_y(y)    #difference between softmax value  and one hot encoder  i.e calculate bias\n",
        "        diff_bias = diff_U             #set new bias value\n",
        "        \n",
        "        diff_W=np.zeros((output_size,input_dim-filter_size+1,input_dim-filter_size+1,num_filters))  #initialize weight variable\n",
        "        for i in range(output_size):  #loop through neuron\n",
        "        \tdiff_W[i,:,:,:]=diff_U[i]*H  #update new weight\n",
        "\n",
        "\n",
        "        delta=np.zeros(H.shape)\n",
        "        for i in range(input_dim-filter_size+1):\n",
        "        \tfor j in range(input_dim-filter_size+1):\n",
        "        \t\tfor p in range(num_filters):\n",
        "       \t\t\t\tdelta[i,j,p]=np.sum(np.multiply(diff_U,W[:,i,j,p]))\n",
        "\n",
        "       \tgrad_Zdel = np.multiply(gradient_Relu(Z),delta)\n",
        "       \tdiff_K = conv(x, grad_Zdel)    #new updated filter\n",
        "\n",
        "\n",
        "       \t#parameter updation\n",
        "\n",
        "       \tbias=bias - LR*diff_bias   #updating bias values\n",
        "       \tW = W - LR*diff_W          #updating weights\n",
        "       \tK = K - LR*diff_K          #updating filter\n",
        "\n",
        "    print(\"Training accuracy for epoch {} : {}\".format(epochs+1, total_correct/np.float(len(x_train))))\n",
        "\n",
        "#test data\n",
        "total_correct = 0\n",
        "for n in range(len(x_test)):\n",
        "    y = y_test[n]\n",
        "    x = x_test[n][:]\n",
        "    x = np.reshape(x, (input_dim, input_dim))\n",
        "\n",
        "    Z=conv(x,K)\n",
        "    H=Relu(Z)\n",
        "        \n",
        "    for i in range(output_size):\n",
        "       \ttemp1=W[i,:,:,:]\n",
        "        temp2=np.multiply(temp1,H)\n",
        "        U[i]=np.sum(temp2) + bias[i]\n",
        "        \n",
        "    rho = softmax_function(U)\n",
        "    predicted_value = np.argmax(rho)\n",
        "\n",
        "    if (predicted_value == y):\n",
        "        total_correct += 1\n",
        "\n",
        "print(\"Test accuracy : {}\".format(total_correct/np.float(len(x_test))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}